{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Create users.csv**"
      ],
      "metadata": {
        "id": "bEZCNc6w8aK8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLezauyy7aX9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# GitHub API token for authentication\n",
        "TOKEN = \"put your token here\"\n",
        "HEADERS = {\"Authorization\": f\"token {TOKEN}\"}\n",
        "\n",
        "# API base URL for users in Austin with over 100 followers\n",
        "BASE_URL = \"https://api.github.com/search/users\"\n",
        "USER_DETAILS_URL = \"https://api.github.com/users/\"\n",
        "\n",
        "# Initialize an empty list to store user data\n",
        "user_data = []\n",
        "\n",
        "# Pagination loop\n",
        "page = 1\n",
        "while True:\n",
        "    # Search query\n",
        "    params = {\n",
        "        \"q\": \"location:Austin followers:>100\",\n",
        "        \"per_page\": 30,\n",
        "        \"page\": page\n",
        "    }\n",
        "    response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
        "\n",
        "    # Check for errors in response\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "        break\n",
        "\n",
        "    users = response.json().get('items', [])\n",
        "    print(f\"Page {page}, Users found: {len(users)}\")  # Debugging: check user count\n",
        "\n",
        "    # Stop if there are no more users\n",
        "    if not users:\n",
        "        break\n",
        "\n",
        "    # Fetch detailed information for each user\n",
        "    for user in users:\n",
        "        user_response = requests.get(USER_DETAILS_URL + user['login'], headers=HEADERS)\n",
        "\n",
        "        # Check for errors in user detail response\n",
        "        if user_response.status_code != 200:\n",
        "            print(\"Error fetching user:\", user['login'], user_response.text)\n",
        "            continue\n",
        "\n",
        "        user_info = user_response.json()\n",
        "\n",
        "        # Format data as per specifications\n",
        "        user_data.append({\n",
        "            \"login\": user_info.get(\"login\", \"\"),\n",
        "            \"name\": user_info.get(\"name\", \"\"),\n",
        "            \"company\": (user_info.get(\"company\", \"\").replace('@', '').strip().upper()\n",
        "                        if user_info.get(\"company\") else \"\"),\n",
        "            \"location\": user_info.get(\"location\", \"\"),\n",
        "            \"email\": user_info.get(\"email\", \"\"),\n",
        "            \"hireable\": \"true\" if user_info.get(\"hireable\") else \"false\" if user_info.get(\"hireable\") is not None else \"\",\n",
        "            \"bio\": user_info.get(\"bio\", \"\"),\n",
        "            \"public_repos\": user_info.get(\"public_repos\", 0),\n",
        "            \"followers\": user_info.get(\"followers\", 0),\n",
        "            \"following\": user_info.get(\"following\", 0),\n",
        "            \"created_at\": user_info.get(\"created_at\", \"\")\n",
        "        })\n",
        "\n",
        "    # Move to the next page\n",
        "    page += 1\n",
        "\n",
        "# Check if user_data is populated\n",
        "print(\"Total users collected:\", len(user_data))\n",
        "\n",
        "# Convert list of dictionaries to DataFrame and check for data presence before saving\n",
        "if user_data:\n",
        "    df = pd.DataFrame(user_data)\n",
        "    df.to_csv(\"users.csv\", index=False)\n",
        "    print(\"Data saved to users.csv\")\n",
        "else:\n",
        "    print(\"No data to save.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create repositories.csv**"
      ],
      "metadata": {
        "id": "s728KmJk8flQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# GitHub API token for authentication\n",
        "TOKEN = \"put your token here\"\n",
        "HEADERS = {\"Authorization\": f\"token {TOKEN}\"}\n",
        "\n",
        "# Load unique users from users.csv\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "unique_logins = users_df['login'].unique()  # Ensure only unique logins\n",
        "repository_data = []\n",
        "\n",
        "# Loop through each unique user login\n",
        "for login in unique_logins:\n",
        "    page = 1\n",
        "    repo_count = 0\n",
        "\n",
        "    while repo_count < 500:\n",
        "        # Fetch repositories for the user, sorted by most recently pushed\n",
        "        repo_url = f\"https://api.github.com/users/{login}/repos\"\n",
        "        params = {\n",
        "            \"sort\": \"pushed\",\n",
        "            \"per_page\": 100,\n",
        "            \"page\": page\n",
        "        }\n",
        "        response = requests.get(repo_url, headers=HEADERS, params=params)\n",
        "\n",
        "        # Check for errors in response\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error:\", response.status_code, response.text)\n",
        "            break\n",
        "\n",
        "        repos = response.json()\n",
        "        if not repos:\n",
        "            break  # Stop if no more repositories\n",
        "\n",
        "        # Process each repository\n",
        "        for repo in repos:\n",
        "            if repo_count >= 500:\n",
        "                break  # Stop after collecting 500 repositories\n",
        "\n",
        "            repository_data.append({\n",
        "                \"login\": login,\n",
        "                \"full_name\": repo.get(\"full_name\", \"\"),\n",
        "                \"created_at\": repo.get(\"created_at\", \"\"),\n",
        "                \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n",
        "                \"watchers_count\": repo.get(\"watchers_count\", 0),\n",
        "                \"language\": repo.get(\"language\", \"\"),\n",
        "                \"has_projects\": \"true\" if repo.get(\"has_projects\") else \"false\",\n",
        "                \"has_wiki\": \"true\" if repo.get(\"has_wiki\") else \"false\",\n",
        "                \"license_name\": repo[\"license\"][\"key\"] if repo.get(\"license\") else \"\"\n",
        "            })\n",
        "            repo_count += 1\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # Optional: sleep to avoid rate limiting\n",
        "\n",
        "# Convert list of dictionaries to DataFrame\n",
        "df_repos = pd.DataFrame(repository_data)\n",
        "\n",
        "# Save DataFrame to repositories.csv\n",
        "df_repos.to_csv(\"repositories.csv\", index=False)\n",
        "print(\"Data saved to repositories.csv\")"
      ],
      "metadata": {
        "id": "y83NDZBr7ct-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attempt to solve Q13**"
      ],
      "metadata": {
        "id": "Nrj5_N4n8lOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the repositories.csv file into a DataFrame\n",
        "df = pd.read_csv('users.csv')\n",
        "\n",
        "# Define a function to calculate the length of a bio in Unicode words, split by whitespace\n",
        "def unicode_word_count(bio):\n",
        "    if pd.isna(bio) or bio == '':  # Check for NaN values (empty bios)\n",
        "        return 0\n",
        "    # Split bio by any kind of whitespace and filter out empty strings\n",
        "    words = re.split(r'\\s+', bio.strip())\n",
        "    return len(words)\n",
        "\n",
        "# Apply the function to each bio and create a new column 'bio_word_count' to store the result\n",
        "df['bio_word_count'] = df['bio'].apply(unicode_word_count)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file if you want\n",
        "df.to_csv('userswithbio.csv', index=False)\n",
        "\n",
        "# Display the DataFrame with bio word counts\n",
        "df[['login', 'bio', 'bio_word_count']]\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the repositories_with_bio_word_count.csv file into a DataFrame\n",
        "df = pd.read_csv('userswithbio.csv')\n",
        "\n",
        "# Filter out users without bios\n",
        "df_filtered = df[df['bio_word_count'] > 0]\n",
        "\n",
        "# Prepare the data for regression\n",
        "X = df_filtered['bio_word_count']  # Independent variable\n",
        "y = df_filtered['followers']  # Dependent variable\n",
        "\n",
        "# Add a constant to the independent variable (required for statsmodels)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient for bio_word_count)\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Slope of followers on bio word count: {slope:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Ggx5lJpL7fnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the users CSV file\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "\n",
        "# Filter out users without bios\n",
        "users_with_bios = users_df[users_df['bio'].notna()]\n",
        "\n",
        "# Calculate the length of each bio in words (Unicode words)\n",
        "users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()\n",
        "\n",
        "# Prepare the data for regression\n",
        "X = users_with_bios[['bio_word_count']]  # Predictor variable (length of bio in words)\n",
        "y = users_with_bios['followers']          # Response variable (number of followers)\n",
        "\n",
        "# Initialize and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the slope (coefficient) of the regression line\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Impact of bio length on followers (slope): {slope:.3f}\")"
      ],
      "metadata": {
        "id": "XmyjzxS47oAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f4wc6GEG7hvH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}